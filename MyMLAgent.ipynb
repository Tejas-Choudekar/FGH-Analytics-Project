{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675ca907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import grid2op\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from grid2op.dtypes import dt_int\n",
    "from grid2op.dtypes import dt_bool\n",
    "from grid2op.dtypes import dt_float\n",
    "\n",
    "from grid2op.Agent import BaseAgent\n",
    "from grid2op.Converter import IdToAct\n",
    "from grid2op.PlotGrid import PlotMatplot\n",
    "from grid2op.Runner import Runner\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19a0095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d66b951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_type = <class 'grid2op.Space.GridObjects.ActionWCCI2020_l2rpn_wcci_2020'>\n",
      "obs_type = <class 'grid2op.Space.GridObjects.ObservationWCCI2020_l2rpn_wcci_2020'>\n",
      "rho = 59\n",
      "action size = 494\n",
      "obs size = 1266\n",
      "reward = 89.17830657958984\n",
      "done = False\n",
      "info = {'disc_lines': array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1], dtype=int32), 'is_illegal': False, 'is_ambiguous': False, 'is_dispatching_illegal': False, 'is_illegal_reco': False, 'reason_alarm_illegal': None, 'opponent_attack_line': None, 'opponent_attack_sub': None, 'opponent_attack_duration': 0, 'exception': [], 'rewards': {}}\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "env_name = \"l2rpn_wcci_2020\"\n",
    "env = grid2op.make(env_name, test=True)\n",
    "act = env.action_space()\n",
    "obs = env.reset()\n",
    "obs, reward, done, info = env.step(act)\n",
    "\n",
    "print(f'act_type = {type(act)}''')\n",
    "print(f'obs_type = {type(obs)}''')\n",
    "\n",
    "print(f'rho = {len(obs.rho)}')\n",
    "#print(f'line_status = {obs.line_status}')\n",
    "#print(f'topo_vect = {len(obs.topo_vect)}')\n",
    "\n",
    "print(f'action size = {act.size()}')\n",
    "print(f'obs size = {obs.size()}')\n",
    "print(f'reward = {reward}')\n",
    "print(f'done = {done}')\n",
    "print(f'info = {info}')\n",
    "print(env.n_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab999156",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_helper = PlotMatplot(env.observation_space)\n",
    "#_ = plot_helper.plot_info(gen_values=env.gen_pmax, line_values=env._thermal_limit_a, load_values=[el for el in range(env.n_load)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a93e863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLAgent(BaseAgent):\n",
    "    \n",
    "    def __init__(self, action_space):\n",
    "        BaseAgent.__init__(self, action_space)\n",
    "    \n",
    "    def act(self, observation, reward, done=False):\n",
    "        # action_space.n_line = len(observation.rho) = 59\n",
    "        action = self.find_best_action(observation)\n",
    "        return action\n",
    "    \n",
    "    def find_best_action(self, observation):\n",
    "        self.tested_action = self._get_tested_action(observation)\n",
    "        if len(self.tested_action) > 1:\n",
    "            self.resulting_rewards = np.full(\n",
    "                shape=len(self.tested_action), fill_value=np.NaN, dtype=dt_float\n",
    "            )\n",
    "            \n",
    "            for i, action in enumerate(self.tested_action):\n",
    "                (\n",
    "                    simul_obs,\n",
    "                    simul_reward,\n",
    "                    simul_has_error,\n",
    "                    simul_info,\n",
    "                ) = observation.simulate(action)\n",
    "                self.resulting_rewards[i] = simul_reward\n",
    "            \n",
    "            reward_idx = int(\n",
    "                np.argmax(self.resulting_rewards)\n",
    "            )  # rewards.index(max(rewards))\n",
    "            best_action_sofar = self.tested_action[reward_idx]\n",
    "            \n",
    "        else:\n",
    "            best_action_sofar = self.tested_action[0]\n",
    "        \n",
    "        best_action = self.find_best_line_to_reconnect(observation, best_action_sofar)\n",
    "        #print(f'best_action = {best_action}')\n",
    "        return best_action\n",
    "    \n",
    "    def find_best_line_to_reconnect(self, observation, original_action):\n",
    "        # Fine all disconnected lines\n",
    "        disconnected_lines = np.where(observation.line_status == False)[0]\n",
    "        \n",
    "        # Return the best action so far if no disconnected lines\n",
    "        if not len(disconnected_lines):\n",
    "            return original_action\n",
    "        \n",
    "        # Return the best action so far if those lines need timesteps to cooldown\n",
    "        if (observation.time_before_cooldown_line[disconnected_lines] > 0).all(): # all: iterable or not.\n",
    "            return original_action\n",
    "        \n",
    "        # Get rho of the best action so far \n",
    "        o, r, _, _ = obs.simulate(original_action)\n",
    "        min_rho = o.rho.max()\n",
    "        min_reward = r\n",
    "        line_to_reconnect = -1\n",
    "        \n",
    "        # Iterate disconnected lines \n",
    "        for line in disconnected_lines:\n",
    "            if not obs.time_before_cooldown_line[line]:\n",
    "                reconnect_array = np.zeros_like(obs.rho, dtype=dt_int)\n",
    "                reconnect_array[line] = 1\n",
    "                reconnect_action = deepcopy(original_action)\n",
    "                reconnect_action.update({'set_line_status': reconnect_array})\n",
    "                \n",
    "                # Simulate the reconnect action and find the minimum rho\n",
    "                o, _, _, _ = obs.simulate(reconnect_action)\n",
    "                if o.rho.max() < min_rho:\n",
    "                    line_to_reconnect = line\n",
    "                    min_rho = o.rho.max()\n",
    "                    \n",
    "            if line_to_reconnect != -1:\n",
    "                reconnect_array = np.zeros_like(obs.rho, dtype=dt_int)\n",
    "                reconnect_array[line_to_reconnect] = 1\n",
    "                original_action.update({'set_line_status': reconnect_array})\n",
    "                \n",
    "            return original_action        \n",
    "    '''\n",
    "    def avoid_blackout(self, observation):\n",
    "        threshold = 0.95\n",
    "        if observation.rho.max() > threshold:\n",
    "            l_id = np.where(observation.rho == observation.rho.max()[0])\n",
    "            disconnect_line = self.action_space({\"set_line_status\": [(l_id, -1)]})\n",
    "    '''\n",
    "    def _get_tested_action(self, observation):\n",
    "        res = [self.action_space({})]  # add the do nothing\n",
    "        for i in range(self.action_space.n_line):\n",
    "            for toggle_action in range(3): #Added this toggle to choose 3 actions\n",
    "                tmp = np.full(self.action_space.n_line, fill_value=False, dtype=dt_bool)\n",
    "                tmp[i] = True\n",
    "                if toggle_action == 0:\n",
    "                    action = self.action_space({\"change_line_status\": tmp})\n",
    "                    if not observation.line_status[i]:\n",
    "                        action = action.update(\n",
    "                            {\"set_bus\": {\"lines_or_id\": [(i, 1)], \"lines_ex_id\": [(i, 1)]}})\n",
    "                    res.append(action)\n",
    "                elif toggle_action == 1:\n",
    "                    if observation.line_status[i]:\n",
    "                        action = self.action_space({\"change_bus\": {\"lines_or_id\": i}}) \n",
    "                        res.append(action)\n",
    "                elif toggle_action == 2:\n",
    "                    if observation.line_status[i]:\n",
    "                        action = self.action_space({\"change_bus\": {\"lines_ex_id\": i}}) \n",
    "                        res.append(action)\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "334a9428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_agent = MyMLAgent(env.action_space)\n",
    "\n",
    "runner = Runner(**env.get_params_for_runner(), agentClass=MyMLAgent)\n",
    "res = runner.run(nb_episode=1, max_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4577c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFor chronics with id Scenario_april_000\n",
      "\t\t - cumulative reward: 268.403198\n",
      "\t\t - number of time steps completed: 3 / 3\n"
     ]
    }
   ],
   "source": [
    "for _, chron_name, cum_reward, nb_time_step, max_ts in res:\n",
    "    msg_tmp = \"\\tFor chronics with id {}\\n\".format(chron_name)\n",
    "    msg_tmp += \"\\t\\t - cumulative reward: {:.6f}\\n\".format(cum_reward)\n",
    "    msg_tmp += \"\\t\\t - number of time steps completed: {:.0f} / {:.0f}\".format(nb_time_step, max_ts)\n",
    "    print(msg_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59683ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1193c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
