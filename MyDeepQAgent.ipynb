{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "97910269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import grid2op\n",
    "\n",
    "from grid2op.Runner import Runner\n",
    "from grid2op.Converter import IdToAct\n",
    "from grid2op.Agent.agentWithConverter import AgentWithConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d85e7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Activation, Dense, subtract, add\n",
    "from tensorflow.keras.layers import Input, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c65dc28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space = 157\n",
      "observation space = 455\n"
     ]
    }
   ],
   "source": [
    "env_name = \"rte_case14_realistic\"\n",
    "env = grid2op.make(env_name)\n",
    "obs = env.reset()\n",
    "\n",
    "print(f'action space = {env.action_space.size()}')\n",
    "print(f'observation space = {obs.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "17db5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingParam(object):\n",
    "    \"\"\"\n",
    "    A class to store the training parameters of the models. It was hard coded in the notebook 3.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 DECAY_RATE=0.9,\n",
    "                 BUFFER_SIZE=40000,\n",
    "                 MINIBATCH_SIZE=64,\n",
    "                 TOT_FRAME=3000000,\n",
    "                 EPSILON_DECAY=10000,\n",
    "                 MIN_OBSERVATION=50, #5000\n",
    "                 FINAL_EPSILON=1/300,  # have on average 1 random action per scenario of approx 287 time steps\n",
    "                 INITIAL_EPSILON=0.1,\n",
    "                 TAU=0.01,\n",
    "                 ALPHA=1,\n",
    "                 NUM_FRAMES=1,\n",
    "    ):\n",
    "        print('TrainingParam __init__')\n",
    "        self.DECAY_RATE = DECAY_RATE\n",
    "        self.BUFFER_SIZE = BUFFER_SIZE\n",
    "        self.MINIBATCH_SIZE = MINIBATCH_SIZE\n",
    "        self.TOT_FRAME = TOT_FRAME\n",
    "        self.EPSILON_DECAY = EPSILON_DECAY\n",
    "        self.MIN_OBSERVATION = MIN_OBSERVATION   # 5000\n",
    "        self.FINAL_EPSILON = FINAL_EPSILON  # have on average 1 random action per scenario of approx 287 time steps\n",
    "        self.INITIAL_EPSILON = INITIAL_EPSILON\n",
    "        self.TAU = TAU\n",
    "        self.NUM_FRAMES = NUM_FRAMES\n",
    "        self.ALPHA = ALPHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a8fbb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Constructs a buffer object that stores the past moves\n",
    "    and samples a set of subsamples\"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.count = 0\n",
    "\n",
    "    '''\n",
    "    def add(self, s, a, r, d, s2):\n",
    "        print('ReplayBuffer add')\n",
    "        \"\"\"Add an experience to the buffer\"\"\"\n",
    "        # S represents current state, a is action,\n",
    "        # r is reward, d is whether it is the end, \n",
    "        # and s2 is next state\n",
    "        if np.any(~np.isfinite(s)) or np.any(~np.isfinite(s2)):\n",
    "            # TODO proper handling of infinite values somewhere !!!!\n",
    "            return\n",
    "\n",
    "        experience = (s, a, r, d, s2)\n",
    "        if self.count < self.buffer_size:\n",
    "            self.buffer.append(experience)\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.buffer.popleft()\n",
    "            self.buffer.append(experience)\n",
    "\n",
    "    def size(self):\n",
    "        print('ReplayBuffer size')\n",
    "        return self.count\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        print('ReplayBuffer sample')\n",
    "\n",
    "        batch = []\n",
    "        if self.count < batch_size:\n",
    "            batch = random.sample(self.buffer, self.count)\n",
    "        else:\n",
    "            batch = random.sample(self.buffer, batch_size)\n",
    "\n",
    "        # Maps each experience in batch in batches of states, actions, rewards\n",
    "        # and new states\n",
    "        s_batch, a_batch, r_batch, d_batch, s2_batch = list(map(np.array, list(zip(*batch))))\n",
    "        return s_batch, a_batch, r_batch, d_batch, s2_batch\n",
    "\n",
    "    def clear(self):\n",
    "        print('ReplayBuffer clear')\n",
    "        self.buffer.clear()\n",
    "        self.count = 0\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "dcdbba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingParam __init__\n"
     ]
    }
   ],
   "source": [
    "class RLQvalue(object):\n",
    "    \"\"\"\n",
    "    This class aims at representing the Q value (or more in case of SAC) parametrization by\n",
    "    a neural network.\n",
    "\n",
    "    It is composed of 2 different networks:\n",
    "    - model: which is the main model\n",
    "    - target_model: which has the same architecture and same initial weights as \"model\" but is updated less frequently\n",
    "      to stabilize training\n",
    "\n",
    "    It has basic methods to make predictions, to train the model, and train the target model.\n",
    "    \"\"\"\n",
    "    def __init__(self, action_size, observation_size,\n",
    "                 learning_rate=1e-5,\n",
    "                 training_param=TrainingParam()):\n",
    "        # TODO add more flexibilities when building the deep Q networks, with a \"NNParam\" for example.\n",
    "        self.action_size = action_size\n",
    "        self.observation_size = observation_size\n",
    "        self.learning_rate_ = learning_rate\n",
    "        self.qvalue_evolution = np.zeros((0,))\n",
    "        self.training_param = training_param\n",
    "\n",
    "        self.model = None\n",
    "        self.target_model = None\n",
    "    \n",
    "    '''\n",
    "    def construct_q_network(self):\n",
    "        print('RLQvalue construct_q_network')\n",
    "        raise NotImplementedError(\"Not implemented\")\n",
    "    '''\n",
    "\n",
    "    def predict_movement(self, data, epsilon):\n",
    "        #print(f'>> data = {data.shape[0]}')\n",
    "        \"\"\"Predict movement of game controler where is epsilon\n",
    "        probability randomly move.\"\"\"\n",
    "        rand_val = np.random.random(data.shape[0])\n",
    "        print(f'>> rand_val = {rand_val}')\n",
    "        q_actions = self.model.predict(data)\n",
    "        #print(f'>> q_actions = {q_actions}')\n",
    "        opt_policy = np.argmax(np.abs(q_actions), axis=-1)\n",
    "        print(f'>> argmax = {opt_policy}')\n",
    "        opt_policy[rand_val < epsilon] = np.random.randint(0, self.action_size, size=(np.sum(rand_val < epsilon)))\n",
    "        \n",
    "        self.qvalue_evolution = np.concatenate((self.qvalue_evolution, q_actions[0, opt_policy]))\n",
    "        #print(f'>> qvalue_evolution = {self.qvalue_evolution}')\n",
    "        #print(f'>> opt_policy = {opt_policy}')\n",
    "        #print(f'>> q_actions = {q_actions[0, opt_policy]}')\n",
    "        return opt_policy, q_actions[0, opt_policy]\n",
    "    \n",
    "    '''\n",
    "    def train(self, s_batch, a_batch, r_batch, d_batch, s2_batch, observation_num):\n",
    "        print('RLQvalue train')\n",
    "        \"\"\"Trains network to fit given parameters\"\"\"\n",
    "        targets = self.model.predict(s_batch)\n",
    "        fut_action = self.target_model.predict(s2_batch)\n",
    "        targets[:, a_batch] = r_batch\n",
    "        targets[d_batch, a_batch[d_batch]] += self.training_param.DECAY_RATE * np.max(fut_action[d_batch], axis=-1)\n",
    "\n",
    "        loss = self.model.train_on_batch(s_batch, targets)\n",
    "        # Print the loss every 100 iterations.\n",
    "        if observation_num % 100 == 0:\n",
    "            print(\"We had a loss equal to \", loss)\n",
    "        return np.all(np.isfinite(loss))\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_path_model(path, name=None):\n",
    "        print('RLQvalue _get_path_model')\n",
    "        if name is None:\n",
    "            path_model = path\n",
    "        else:\n",
    "            path_model = os.path.join(path, name)\n",
    "        path_target_model = \"{}_target\".format(path_model)\n",
    "        return path_model, path_target_model\n",
    "\n",
    "    def save_network(self, path, name=None, ext=\"h5\"):\n",
    "        print('RLQvalue save_network')\n",
    "        # Saves model at specified path as h5 file\n",
    "        # nothing has changed\n",
    "        path_model, path_target_model = self._get_path_model(path, name)\n",
    "        self.model.save('{}.{}'.format(path_model, ext))\n",
    "        self.target_model.save('{}.{}'.format(path_target_model, ext))\n",
    "        print(\"Successfully saved network.\")\n",
    "\n",
    "    \n",
    "    def load_network(self, path, name=None, ext=\"h5\"):\n",
    "        print('RLQvalue load_network')\n",
    "        # nothing has changed\n",
    "        path_model, path_target_model = self._get_path_model(path, name)\n",
    "        self.model = load_model('{}.{}'.format(path_model, ext))\n",
    "        self.target_model = load_model('{}.{}'.format(path_target_model, ext))\n",
    "        print(\"Succesfully loaded network.\")\n",
    "\n",
    "    def target_train(self):\n",
    "        print('RLQvalue target_train')\n",
    "        # nothing has changed from the original implementation\n",
    "        model_weights = self.model.get_weights()\n",
    "        target_model_weights = self.target_model.get_weights()\n",
    "        for i in range(len(model_weights)):\n",
    "            target_model_weights[i] = self.training_param.TAU * model_weights[i] + (1 - self.training_param.TAU) * \\\n",
    "                                      target_model_weights[i]\n",
    "        self.target_model.set_weights(target_model_weights)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0b0abbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingParam __init__\n"
     ]
    }
   ],
   "source": [
    "class DuelQ(RLQvalue):\n",
    "    \"\"\"Constructs the desired duelling deep q learning network\"\"\"\n",
    "    def __init__(self, action_size, observation_size,\n",
    "                 learning_rate=0.00001,\n",
    "                 training_param=TrainingParam()):\n",
    "        ## print('DuelQ __init__')\n",
    "        RLQvalue.__init__(self, action_size, observation_size, learning_rate, training_param)\n",
    "        self.construct_q_network()\n",
    "\n",
    "    def construct_q_network(self):\n",
    "        # Uses the network architecture found in DeepMind paper\n",
    "        # The inputs and outputs size have changed, as well as replacing the convolution by dense layers.\n",
    "        self.model = Sequential()\n",
    "        \n",
    "        input_layer = Input(shape=(self.observation_size*self.training_param.NUM_FRAMES,))\n",
    "        \n",
    "        lay1 = Dense(self.observation_size*self.training_param.NUM_FRAMES)(input_layer)\n",
    "        lay1 = Activation('relu')(lay1)\n",
    "        \n",
    "        lay2 = Dense(self.observation_size)(lay1)\n",
    "        lay2 = Activation('relu')(lay2)\n",
    "        \n",
    "        lay3 = Dense(2*self.action_size)(lay2)\n",
    "        lay3 = Activation('relu')(lay3)\n",
    "        \n",
    "        fc1 = Dense(self.action_size)(lay3)\n",
    "        advantage = Dense(self.action_size)(fc1)\n",
    "        fc2 = Dense(self.action_size)(lay3)\n",
    "        value = Dense(1)(fc2)\n",
    "        \n",
    "        meaner = Lambda(lambda x: K.mean(x, axis=1) )\n",
    "        mn_ = meaner(advantage)\n",
    "        tmp = subtract([advantage, mn_])\n",
    "        policy = add([tmp, value])\n",
    "\n",
    "        self.model = Model(inputs=[input_layer], outputs=[policy])\n",
    "        self.model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate_))\n",
    "\n",
    "        self.target_model = Model(inputs=[input_layer], outputs=[policy])\n",
    "        self.target_model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate_))\n",
    "        print(\"Successfully constructed networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d6bad922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingParam __init__\n"
     ]
    }
   ],
   "source": [
    "class MyDeepQAgent(AgentWithConverter):\n",
    "    \n",
    "    ## 1*0^-5 = 0.00001\n",
    "    def __init__(self, action_space, mode=\"DDQN\", learning_rate=1e-5, training_param=TrainingParam()):     \n",
    "        print(f'>>>>> {action_space.size()}')\n",
    "        \n",
    "        ## Handle only vectors, and the type of action_space is GridObjects\n",
    "        AgentWithConverter.__init__(self, action_space, action_space_converter=IdToAct)\n",
    "\n",
    "        # and now back to the origin implementation\n",
    "        self.replay_buffer = ReplayBuffer(training_param.BUFFER_SIZE)\n",
    "\n",
    "        # compare to original implementation, i don't know the observation space size.\n",
    "        # Because it depends on the component of the observation we want to look at. So these neural network will\n",
    "        # be initialized the first time an observation is observe.\n",
    "        self.deep_q = None\n",
    "        self.mode = mode\n",
    "        self.learning_rate = learning_rate\n",
    "        self.training_param = training_param\n",
    "    \n",
    "    def convert_obs(self, observation):\n",
    "        convert_obs = np.concatenate((observation.rho, observation.line_status, observation.topo_vect))\n",
    "        print(f'convert_obs = {convert_obs}')\n",
    "        ## print(f'>> convert_obs = {np.concatenate((observation.rho, observation.line_status, observation.topo_vect))}')\n",
    "        return np.concatenate((observation.rho, observation.line_status, observation.topo_vect))\n",
    "\n",
    "    def my_act(self, transformed_observation, reward, done=False):\n",
    "        print(f'>> transformed_observation = {transformed_observation}')\n",
    "        if self.deep_q is None:\n",
    "            self.init_deep_q(transformed_observation)\n",
    "        \n",
    "        predict_movement_int, *_ = self.deep_q.predict_movement(transformed_observation.reshape(1, -1), epsilon=0.0)\n",
    "        #print(f'>> predict_movement_int = {predict_movement_int}')\n",
    "        #print(*_)\n",
    "        print(f'### {int(predict_movement_int)}')\n",
    "        return int(predict_movement_int)\n",
    "\n",
    "    def init_deep_q(self, transformed_observation):\n",
    "        if self.deep_q is None:\n",
    "            # the first time an observation is observed, I set up the neural network with the proper dimensions.\n",
    "            if self.mode == \"DQN\":\n",
    "                cls = DeepQ\n",
    "            elif self.mode == \"DDQN\":\n",
    "                cls = DuelQ\n",
    "            elif self.mode == \"SAC\":\n",
    "                cls = SAC\n",
    "            else:\n",
    "                raise RuntimeError(\"Unknown neural network named \\\"{}\\\". Supported types are \\\"DQN\\\", \\\"DDQN\\\" and \"\n",
    "                                   \"\\\"SAC\\\"\".format(self.mode))\n",
    "            self.deep_q = cls(self.action_space.size(), observation_size=transformed_observation.shape[-1], learning_rate=self.learning_rate)\n",
    "            print(f'>> action_size = {self.deep_q.action_size}, observation_size = {self.deep_q.observation_size}, learning_rate_ = {self.deep_q.learning_rate_}, qvalue_evolution = {self.deep_q.qvalue_evolution}, training_param = {self.deep_q.training_param}, model = {self.deep_q.model}, target_model = {self.deep_q.target_model}')\n",
    "            print(f'>> self.deep_q = {self.deep_q}')\n",
    "            \n",
    "    '''\n",
    "    def load_network(self, path):\n",
    "        print('MyDeepQAgent load_network')\n",
    "        # not modified compare to original implementation\n",
    "        self.deep_q.load_network(path)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "473fe712",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> 157\n",
      ">>>>> 157\n",
      "convert_obs = [0.47497413 0.40584007 0.25593144 0.43165019 0.87776601 0.19951059\n",
      " 0.31530991 0.34744552 0.54350817 0.79384357 0.35989806 0.61349881\n",
      " 0.34683934 0.17008308 0.37997377 0.3229613  0.26576716 0.8698833\n",
      " 0.26976758 0.20893757 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> transformed_observation = [0.47497413 0.40584007 0.25593144 0.43165019 0.87776601 0.19951059\n",
      " 0.31530991 0.34744552 0.54350817 0.79384357 0.35989806 0.61349881\n",
      " 0.34683934 0.17008308 0.37997377 0.3229613  0.26576716 0.8698833\n",
      " 0.26976758 0.20893757 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      "Successfully constructed networks.\n",
      ">> action_size = 451, observation_size = 96, learning_rate_ = 1e-05, qvalue_evolution = [], training_param = <__main__.TrainingParam object at 0x7f7989867370>, model = <keras.engine.functional.Functional object at 0x7f79897f4520>, target_model = <keras.engine.functional.Functional object at 0x7f7988843e80>\n",
      ">> self.deep_q = <__main__.DuelQ object at 0x7f798ae729d0>\n",
      ">> rand_val = [0.79905404]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      ">> argmax = [153]\n",
      "### 153\n",
      "convert_obs = [0.45143566 0.39919409 0.24462105 0.42947018 0.87631273 0.20642236\n",
      " 0.30897233 0.34864962 0.54149985 0.79855341 0.3521812  0.62351686\n",
      " 0.34830958 0.1775084  0.38333434 0.32284945 0.26599896 0.86817706\n",
      " 0.27006915 0.20950978 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> transformed_observation = [0.45143566 0.39919409 0.24462105 0.42947018 0.87631273 0.20642236\n",
      " 0.30897233 0.34864962 0.54149985 0.79855341 0.3521812  0.62351686\n",
      " 0.34830958 0.1775084  0.38333434 0.32284945 0.26599896 0.86817706\n",
      " 0.27006915 0.20950978 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> rand_val = [0.2401867]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      ">> argmax = [153]\n",
      "### 153\n",
      "convert_obs = [0.47449693 0.40526897 0.25274053 0.4305782  0.87656915 0.20148161\n",
      " 0.31297934 0.35019085 0.54331046 0.79645663 0.34522885 0.6282773\n",
      " 0.34811726 0.17397609 0.38712868 0.32495683 0.26807085 0.87566203\n",
      " 0.27092403 0.21108738 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> transformed_observation = [0.47449693 0.40526897 0.25274053 0.4305782  0.87656915 0.20148161\n",
      " 0.31297934 0.35019085 0.54331046 0.79645663 0.34522885 0.6282773\n",
      " 0.34811726 0.17397609 0.38712868 0.32495683 0.26807085 0.87566203\n",
      " 0.27092403 0.21108738 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> rand_val = [0.24277972]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      ">> argmax = [153]\n",
      "### 153\n",
      "convert_obs = [0.45534232 0.39970917 0.25434703 0.42949268 0.87499475 0.1993656\n",
      " 0.31135955 0.34712154 0.53957671 0.79404235 0.37101004 0.62822556\n",
      " 0.34683609 0.17520778 0.38275027 0.32004151 0.26240364 0.86370885\n",
      " 0.27014196 0.20638953 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> transformed_observation = [0.45534232 0.39970917 0.25434703 0.42949268 0.87499475 0.1993656\n",
      " 0.31135955 0.34712154 0.53957671 0.79404235 0.37101004 0.62822556\n",
      " 0.34683609 0.17520778 0.38275027 0.32004151 0.26240364 0.86370885\n",
      " 0.27014196 0.20638953 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> rand_val = [0.31970865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      ">> argmax = [153]\n",
      "### 153\n",
      "convert_obs = [0.45767537 0.39960846 0.25504503 0.42873615 0.87280071 0.19824241\n",
      " 0.31193328 0.34941438 0.54048586 0.79637259 0.33354494 0.62847805\n",
      " 0.3473196  0.17628941 0.38541308 0.32004404 0.26257795 0.86027747\n",
      " 0.27076048 0.20684801 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> transformed_observation = [0.45767537 0.39960846 0.25504503 0.42873615 0.87280071 0.19824241\n",
      " 0.31193328 0.34941438 0.54048586 0.79637259 0.33354494 0.62847805\n",
      " 0.3473196  0.17628941 0.38541308 0.32004404 0.26257795 0.86027747\n",
      " 0.27076048 0.20684801 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> rand_val = [0.60518304]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      ">> argmax = [153]\n",
      "### 153\n",
      "convert_obs = [0.45468521 0.39792565 0.25446898 0.42769989 0.8697291  0.19715148\n",
      " 0.31277308 0.34705445 0.53354722 0.78651011 0.34660539 0.62465733\n",
      " 0.34878039 0.17370145 0.38689265 0.31884667 0.26155201 0.85576004\n",
      " 0.26978934 0.20606411 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> transformed_observation = [0.45468521 0.39792565 0.25446898 0.42769989 0.8697291  0.19715148\n",
      " 0.31277308 0.34705445 0.53354722 0.78651011 0.34660539 0.62465733\n",
      " 0.34878039 0.17370145 0.38689265 0.31884667 0.26155201 0.85576004\n",
      " 0.26978934 0.20606411 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> rand_val = [0.15427889]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      ">> argmax = [153]\n",
      "### 153\n",
      "convert_obs = [0.46883747 0.40024036 0.25817469 0.42660758 0.86519766 0.19289307\n",
      " 0.31554005 0.34344575 0.53346157 0.78660589 0.34418133 0.62172258\n",
      " 0.34111288 0.1736123  0.37908974 0.3180109  0.26027781 0.84955215\n",
      " 0.26665995 0.20391257 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> transformed_observation = [0.46883747 0.40024036 0.25817469 0.42660758 0.86519766 0.19289307\n",
      " 0.31554005 0.34344575 0.53346157 0.78660589 0.34418133 0.62172258\n",
      " 0.34111288 0.1736123  0.37908974 0.3180109  0.26027781 0.84955215\n",
      " 0.26665995 0.20391257 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> rand_val = [0.60584398]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      ">> argmax = [153]\n",
      "### 153\n",
      "convert_obs = [0.44645703 0.39076346 0.24032824 0.4199082  0.85420948 0.20131081\n",
      " 0.3066611  0.34587595 0.52969569 0.77683812 0.33393005 0.61222243\n",
      " 0.34688765 0.16908662 0.38592163 0.31581169 0.25858194 0.83908659\n",
      " 0.2683208  0.20375746 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> transformed_observation = [0.44645703 0.39076346 0.24032824 0.4199082  0.85420948 0.20131081\n",
      " 0.3066611  0.34587595 0.52969569 0.77683812 0.33393005 0.61222243\n",
      " 0.34688765 0.16908662 0.38592163 0.31581169 0.25858194 0.83908659\n",
      " 0.2683208  0.20375746 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> rand_val = [0.24813083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      ">> argmax = [153]\n",
      "### 153\n",
      "convert_obs = [0.44059944 0.38447061 0.24190699 0.41262263 0.8389433  0.19238032\n",
      " 0.30196327 0.33848456 0.52034122 0.76597494 0.3152433  0.60596043\n",
      " 0.33610886 0.16774082 0.37521619 0.31287616 0.25536194 0.8195982\n",
      " 0.26211599 0.19961062 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> transformed_observation = [0.44059944 0.38447061 0.24190699 0.41262263 0.8389433  0.19238032\n",
      " 0.30196327 0.33848456 0.52034122 0.76597494 0.3152433  0.60596043\n",
      " 0.33610886 0.16774082 0.37521619 0.31287616 0.25536194 0.8195982\n",
      " 0.26211599 0.19961062 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> rand_val = [0.99189761]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      ">> argmax = [153]\n",
      "### 153\n",
      "convert_obs = [0.43113631 0.38020152 0.24213143 0.4100033  0.83317876 0.18920963\n",
      " 0.3007046  0.33411542 0.5155369  0.75719404 0.31632754 0.60455787\n",
      " 0.33519119 0.16603798 0.37404537 0.30840677 0.25076413 0.8090924\n",
      " 0.26088506 0.19611408 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> transformed_observation = [0.43113631 0.38020152 0.24213143 0.4100033  0.83317876 0.18920963\n",
      " 0.3007046  0.33411542 0.5155369  0.75719404 0.31632754 0.60455787\n",
      " 0.33519119 0.16603798 0.37404537 0.30840677 0.25076413 0.8090924\n",
      " 0.26088506 0.19611408 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      ">> rand_val = [0.41814318]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      ">> argmax = [153]\n",
      "### 153\n"
     ]
    }
   ],
   "source": [
    "my_agent = MyDeepQAgent(env.action_space)\n",
    "\n",
    "runner = Runner(**env.get_params_for_runner(), agentClass=MyDeepQAgent)\n",
    "res = runner.run(nb_episode=1, max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b81f7151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFor chronics with id 000\n",
      "\t\t - cumulative reward: 923.063965\n",
      "\t\t - number of time steps completed: 10 / 10\n"
     ]
    }
   ],
   "source": [
    "for _, chron_name, cum_reward, nb_time_step, max_ts in res:\n",
    "    msg_tmp = \"\\tFor chronics with id {}\\n\".format(chron_name)\n",
    "    msg_tmp += \"\\t\\t - cumulative reward: {:.6f}\\n\".format(cum_reward)\n",
    "    msg_tmp += \"\\t\\t - number of time steps completed: {:.0f} / {:.0f}\".format(nb_time_step, max_ts)\n",
    "    print(msg_tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
