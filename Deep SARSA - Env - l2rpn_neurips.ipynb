{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d81892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid2op\n",
    "import random\n",
    "import copy\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Callable\n",
    "import os\n",
    "\n",
    "from torch import nn as nn\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "from grid2op.Agent import BaseAgent\n",
    "from grid2op.gym_compat import GymEnv, BoxGymObsSpace, DiscreteActSpace\n",
    "from gym import Env\n",
    "from gym.utils.env_checker import check_env\n",
    "from grid2op.PlotGrid import PlotMatplot\n",
    "from utils import plot_cost_to_go, plot_max_q, test_agent, plot_stats, seed_everything    \n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a9d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessEnv(gym.Wrapper):\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "    \n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        return torch.from_numpy(obs).unsqueeze(dim=0).float()\n",
    "    \n",
    "    def step(self, action):\n",
    "        action = action.item()\n",
    "        next_state, reward, done, info = self.env.step(action)\n",
    "        next_state = torch.from_numpy(next_state).unsqueeze(dim=0).float()\n",
    "        reward = torch.tensor(reward).view(1, -1).float()\n",
    "        done = torch.tensor(done).view(1, -1)\n",
    "        return next_state, reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0036cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "\n",
    "    def __init__(self, capacity=1000000):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def insert(self, transition):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = transition\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        assert self.can_sample(batch_size)\n",
    "\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        batch = zip(*batch)\n",
    "        return [torch.cat(items) for items in batch]\n",
    "\n",
    "    def can_sample(self, batch_size):\n",
    "        return len(self.memory) >= batch_size * 10\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './training_data_track1'  # for demo only, use your own dataset\n",
    "SCENARIO_PATH = './training_data_track1/chronics'\n",
    "\n",
    "try:\n",
    "    # if lightsim2grid is available, use it.\n",
    "    from lightsim2grid import LightSimBackend\n",
    "    backend = LightSimBackend()\n",
    "    env = grid2op.make(dataset=DATA_PATH, chronics_path=SCENARIO_PATH, backend=backend)\n",
    "except:\n",
    "    env = grid2op.make(dataset=DATA_PATH, chronics_path=SCENARIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae275b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSarsaAgent(BaseAgent):\n",
    "    \n",
    "    def __init__(self, load_state=False, env_name=None, data_path=None, chronics_path=None):\n",
    "        if env_name is None and data_path is None and chronics_path is None:\n",
    "            raise RuntimeError(\"Environment must be passed, you can pas env_name or data_path and chronics_path\")\n",
    "        if env_name is not None:\n",
    "            data_path=None\n",
    "            chronics_path=None\n",
    "            env = grid2op.make(env_name)\n",
    "        if data_path is not None and chronics_path is not None:\n",
    "            env_name=None\n",
    "            env = grid2op.make(dataset=data_path, chronics_path=chronics_path)\n",
    "        self.load_state = load_state\n",
    "        self.model_path = './nn_model'\n",
    "        if not os.path.exists(self.model_path):\n",
    "            os.makedirs(self.model_path)\n",
    "#         self.episodes = episodes\n",
    "        self.gym_env = GymEnv(env)\n",
    "        self.gym_env.observation_space = BoxGymObsSpace(env.observation_space, attr_to_keep=[\"gen_p\", \"load_p\", \"topo_vect\", \"rho\"])\n",
    "        self.gym_env.action_space = DiscreteActSpace(env.action_space, attr_to_keep=[\"set_bus\" , \"change_bus\", \"change_line_status\", \"set_line_status\", \"set_line_status_simple\"])\n",
    "        self.state_dims = self.gym_env.observation_space.shape[0]\n",
    "        self.num_actions = self.gym_env.action_space.n\n",
    "        \n",
    "        self.prepo_gym_env = PreprocessEnv(self.gym_env)\n",
    "        self.batch_size = 10\n",
    "        self.gamma = 0.99\n",
    "        self.q_network = self.q_network_def()\n",
    "        self.target_q_network = self.target_network()\n",
    "        self.optim = AdamW(self.q_network.parameters(), lr=0.001) #optimiser to optimise weight calculation of neural networks\n",
    "        self.memory = ReplayMemory() #Initialising memory to store State, Action, Reward, and Next State\n",
    "        self.stats = {'MSE Loss': [], 'Returns': []} #Dict to store statistics\n",
    "        \n",
    "    \n",
    "    def q_network_def(self):\n",
    "        q_network = nn.Sequential(nn.Linear(self.state_dims, 300),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(300, 250),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(250, self.num_actions))\n",
    "        return q_network\n",
    "    \n",
    "    def target_network(self):\n",
    "        q_network = self.q_network_def()\n",
    "        target_q_network = copy.deepcopy(q_network).eval()\n",
    "        return target_q_network\n",
    "    \n",
    "    def policy(self, state, epsilon=0.05):\n",
    "        self.epsilon = 0.05\n",
    "        q_network = self.q_network_def()\n",
    "        if torch.rand(1) < epsilon:\n",
    "            return torch.randint(self.num_actions, (1, 1))\n",
    "        else:\n",
    "            av = q_network(state).detach()\n",
    "            return torch.argmax(av, dim=-1, keepdim=True)\n",
    "    \n",
    "    def train_network(self, alpha=0.001, batch_size=32, gamma=0.99, epsilon=0.):\n",
    "        state = self.prepo_gym_env.reset() #getting initial state\n",
    "        done = False\n",
    "        ep_return = 0\n",
    "        while not done:\n",
    "            action = self.policy(state, epsilon) #Getting first action greedily with randomisation factor Epsilon\n",
    "            next_state, reward, done, _ = self.prepo_gym_env.step(action) #taking selected action on environment\n",
    "            self.memory.insert([state, action, reward, done, next_state]) #Storing the results to memory\n",
    "            if self.memory.can_sample(self.batch_size): #samples will be created only if memory pool is 10 times of batch size\n",
    "                state_b, action_b, reward_b, done_b, next_state_b = self.memory.sample(self.batch_size) #creating batches to train neural network\n",
    "                qsa_b = self.q_network(state_b).gather(1, action_b) #providing the state to neural network and comparing the \n",
    "                                                                #actions with actions stored in memory and gather the experiences\n",
    "                next_action_b = self.policy(next_state_b) #using greedy epsilon policy to greedily get next actions\n",
    "                next_qsa_b = self.target_q_network(next_state_b).gather(1, next_action_b) #provide next state and next action to a target neural network\n",
    "                                                                                        #and gather its experiences\n",
    "                target_b = reward_b + ~done_b * gamma * next_qsa_b #discount the experiences of target network\n",
    "                loss = F.mse_loss(qsa_b, target_b) #find a Mean square error loss\n",
    "                self.q_network.zero_grad() #reset the gradients of the network\n",
    "                loss.backward() #calculate gradients using backward propogation\n",
    "                self.optim.step() # Iterate over all parameters (tensors) that are supposed \n",
    "                                # to be updated and use internally stored grad to update their values\n",
    "                loss.item() # get the loss\n",
    "                self.stats['MSE Loss'].append(loss.item())\n",
    "                    \n",
    "\n",
    "            state = next_state\n",
    "            ep_return += reward.item()\n",
    "\n",
    "        self.stats['Returns'].append(ep_return)\n",
    "\n",
    "        print (f'self.load state is {self.load_state}')\n",
    "        if self.load_state:\n",
    "            self.target_q_network.load_state_dict(self.q_network.state_dict()) #After every 10 episodes load state of original network to\n",
    "                                                                        # target network\n",
    "        return self.stats\n",
    "    \n",
    "    def act(self, observation, reward, done=False):\n",
    "        load_state = False\n",
    "        global episode_iter\n",
    "        if episode_iter % 10 == 0:\n",
    "            load_state = True\n",
    "        print(f'load state is :{load_state}')\n",
    "        stats = self.train_network(load_state)\n",
    "#         plot_stats(stats)\n",
    "        gym_obs = self.gym_env.observation_space.to_gym(observation)\n",
    "        conv_gym_obs = torch.from_numpy(gym_obs).unsqueeze(dim=0).float()\n",
    "        gym_act = torch.argmax(self.q_network(conv_gym_obs).detach(), dim=-1, keepdim=True)\n",
    "        print(f'Action is:{gym_act}')\n",
    "        grid2op_act = self.gym_env.action_space.from_gym(gym_act)\n",
    "        episode_iter += 1\n",
    "        return grid2op_act\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5ae7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './training_data_track1'  # for demo only, use your own dataset\n",
    "SCENARIO_PATH = './training_data_track1/chronics'\n",
    "deep_sarsa_agent = DeepSarsaAgent(data_path=DATA_PATH, chronics_path=SCENARIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d30ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5acd41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[70888]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[70888]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[70888]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[5445]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[90648]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[70458]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[70458]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[70458]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[120060]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[120060]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[70458]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[70458]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[18803]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[18803]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[18803]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[18803]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[18803]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[18803]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[18803]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[18803]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[89844]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[89844]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[89844]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[89844]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[121657]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[121657]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[121657]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[90961]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[65832]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[65832]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[65832]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[91197]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[91197]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[125525]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[125525]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[40781]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[74150]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6872]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[58493]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6872]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[6872]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6872]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6872]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[117171]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[44328]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[114621]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[114621]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[37648]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[27690]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[75267]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[75267]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[75267]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[75267]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[111860]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[111860]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[75267]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[77878]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[77878]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[77878]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[46430]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[22598]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[22598]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[82930]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[75267]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[75267]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[82930]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[82930]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[82930]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[82930]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[82930]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[82930]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[82930]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[82930]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[134195]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[19851]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[132278]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[132278]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[42423]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[132278]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[132278]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[90867]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[90867]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[27690]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[90867]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[90867]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[90867]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[41555]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[41555]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[120060]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[120060]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[120060]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[12744]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[41968]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[41968]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[41968]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[41968]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[22598]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[22598]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[22598]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[41968]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[121959]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[70458]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[70458]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[70458]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[72729]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[72729]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[72729]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[72729]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[72729]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[132679]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[105283]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[44328]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[44328]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[44328]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[44328]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[44328]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[44328]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[44328]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[44328]])\n",
      "load state is :False\n"
     ]
    }
   ],
   "source": [
    "max_iter = 20 #customize\n",
    "from grid2op.Runner import Runner\n",
    "import os\n",
    "from grid2op.Reward import L2RPNReward\n",
    "from grid2op.Chronics import GridStateFromFileWithForecasts\n",
    "\n",
    "path_saved_data = './Res'\n",
    "if not os.path.exists(path_saved_data):\n",
    "    os.mkdir(path_saved_data)\n",
    "\n",
    "# env_name = \"l2rpn_neurips_2020_track1\"\n",
    "# env = grid2op.make(env_name)\n",
    "env = grid2op.make(dataset=DATA_PATH, chronics_path=SCENARIO_PATH)\n",
    "runner = Runner(**env.get_params_for_runner(),\n",
    "                agentInstance=deep_sarsa_agent, agentClass=None)\n",
    "res = runner.run(nb_episode=40, max_iter=max_iter, path_save=path_saved_data)\n",
    "print(\"The results for the custom agent are:\")\n",
    "for _, chron_name, cum_reward, nb_time_step, max_ts in res:\n",
    "    msg_tmp = \"\\tFor chronics with id {}\\n\".format(chron_name)\n",
    "    msg_tmp += \"\\t\\t - cumulative reward: {:.6f}\\n\".format(cum_reward)\n",
    "    msg_tmp += \"\\t\\t - number of time steps completed: {:.0f} / {:.0f}\".format(nb_time_step, max_ts)\n",
    "    print(msg_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490767b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1001195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a32df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20adf620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52769470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
