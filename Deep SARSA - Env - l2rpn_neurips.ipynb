{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d81892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid2op\n",
    "import random\n",
    "import copy\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Callable\n",
    "import os\n",
    "\n",
    "from torch import nn as nn\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "from grid2op.Agent import BaseAgent\n",
    "from grid2op.gym_compat import GymEnv, BoxGymObsSpace, DiscreteActSpace\n",
    "from gym import Env\n",
    "from gym.utils.env_checker import check_env\n",
    "from grid2op.PlotGrid import PlotMatplot\n",
    "#from utils import plot_cost_to_go, plot_max_q, test_agent, plot_stats, seed_everything    \n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a9d41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumed\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "class PreprocessEnv(gym.Wrapper):\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "    \n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        return torch.from_numpy(obs).unsqueeze(dim=0).float()\n",
    "    \n",
    "    def step(self, action):\n",
    "        action = action.item()\n",
    "        next_state, reward, done, info = self.env.step(action)\n",
    "        next_state = torch.from_numpy(next_state).unsqueeze(dim=0).float()\n",
    "        reward = torch.tensor(reward).view(1, -1).float()\n",
    "        done = torch.tensor(done).view(1, -1)\n",
    "        return next_state, reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0036cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "\n",
    "    def __init__(self, capacity=1000000):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def insert(self, transition):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = transition\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        assert self.can_sample(batch_size)\n",
    "\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        batch = zip(*batch)\n",
    "        return [torch.cat(items) for items in batch]\n",
    "\n",
    "    def can_sample(self, batch_size):\n",
    "        return len(self.memory) >= batch_size * 10\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2861cfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumed\\anaconda3\\lib\\site-packages\\lightsim2grid\\gridmodel\\_aux_add_trafo.py:65: UserWarning: There were some Nan in the pp_net.trafo[\"tap_step_degree\"], they have been replaced by 0\n",
      "  warnings.warn(\"There were some Nan in the pp_net.trafo[\\\"tap_step_degree\\\"], they have been replaced by 0\")\n",
      "C:\\Users\\sumed\\anaconda3\\lib\\site-packages\\lightsim2grid\\gridmodel\\_aux_add_slack.py:113: UserWarning: We found either some slack coefficient to be < 0. or they were all 0.We set them all to 1.0 to avoid such issues\n",
      "  warnings.warn(\"We found either some slack coefficient to be < 0. or they were all 0.\"\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = './training_data_track1'  # for demo only, use your own dataset\n",
    "SCENARIO_PATH = './training_data_track1/chronics'\n",
    "\n",
    "try:\n",
    "    # if lightsim2grid is available, use it.\n",
    "    from lightsim2grid import LightSimBackend\n",
    "    backend = LightSimBackend()\n",
    "    env = grid2op.make(dataset=DATA_PATH, chronics_path=SCENARIO_PATH, backend=backend)\n",
    "except:\n",
    "    env = grid2op.make(dataset=DATA_PATH, chronics_path=SCENARIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae275b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumed\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "class DeepSarsaAgent(BaseAgent):\n",
    "    \n",
    "    def __init__(self, load_state=False, env_name=None, data_path=None, chronics_path=None):\n",
    "        if env_name is None and data_path is None and chronics_path is None:\n",
    "            raise RuntimeError(\"Environment must be passed, you can pas env_name or data_path and chronics_path\")\n",
    "        if env_name is not None:\n",
    "            data_path=None\n",
    "            chronics_path=None\n",
    "            env = grid2op.make(env_name)\n",
    "        if data_path is not None and chronics_path is not None:\n",
    "            env_name=None\n",
    "            env = grid2op.make(dataset=data_path, chronics_path=chronics_path)\n",
    "        self.load_state = load_state\n",
    "        self.model_path = './nn_model'\n",
    "        if not os.path.exists(self.model_path):\n",
    "            os.makedirs(self.model_path)\n",
    "#         self.episodes = episodes\n",
    "        self.gym_env = GymEnv(env)\n",
    "        self.gym_env.observation_space = BoxGymObsSpace(env.observation_space, attr_to_keep=[\"gen_p\", \"load_p\", \"topo_vect\", \"rho\"])\n",
    "        self.gym_env.action_space = DiscreteActSpace(env.action_space, attr_to_keep=[\"set_bus\" , \"change_bus\", \"change_line_status\", \"set_line_status\", \"set_line_status_simple\"])\n",
    "        self.state_dims = self.gym_env.observation_space.shape[0]\n",
    "        self.num_actions = self.gym_env.action_space.n\n",
    "        \n",
    "        self.prepo_gym_env = PreprocessEnv(self.gym_env)\n",
    "        self.batch_size = 10\n",
    "        self.gamma = 0.99\n",
    "        self.q_network = self.q_network_def()\n",
    "        self.target_q_network = self.target_network()\n",
    "        self.optim = AdamW(self.q_network.parameters(), lr=0.001) #optimiser to optimise weight calculation of neural networks\n",
    "        self.memory = ReplayMemory() #Initialising memory to store State, Action, Reward, and Next State\n",
    "        self.stats = {'MSE Loss': [], 'Returns': []} #Dict to store statistics\n",
    "        \n",
    "    \n",
    "    def q_network_def(self):\n",
    "        q_network = nn.Sequential(nn.Linear(self.state_dims, 300),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(300, 250),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(250, self.num_actions))\n",
    "        return q_network\n",
    "    \n",
    "    def target_network(self):\n",
    "        q_network = self.q_network_def()\n",
    "        target_q_network = copy.deepcopy(q_network).eval()\n",
    "        return target_q_network\n",
    "    \n",
    "    def policy(self, state, epsilon=0.05):\n",
    "        self.epsilon = 0.05\n",
    "        q_network = self.q_network_def()\n",
    "        if torch.rand(1) < epsilon:\n",
    "            return torch.randint(self.num_actions, (1, 1))\n",
    "        else:\n",
    "            av = q_network(state).detach()\n",
    "            return torch.argmax(av, dim=-1, keepdim=True)\n",
    "    \n",
    "    def train_network(self, alpha=0.001, batch_size=32, gamma=0.99, epsilon=0.):\n",
    "        state = self.prepo_gym_env.reset() #getting initial state\n",
    "        done = False\n",
    "        ep_return = 0\n",
    "        while not done:\n",
    "            action = self.policy(state, epsilon) #Getting first action greedily with randomisation factor Epsilon\n",
    "            next_state, reward, done, _ = self.prepo_gym_env.step(action) #taking selected action on environment\n",
    "            self.memory.insert([state, action, reward, done, next_state]) #Storing the results to memory\n",
    "            if self.memory.can_sample(self.batch_size): #samples will be created only if memory pool is 10 times of batch size\n",
    "                state_b, action_b, reward_b, done_b, next_state_b = self.memory.sample(self.batch_size) #creating batches to train neural network\n",
    "                qsa_b = self.q_network(state_b).gather(1, action_b) #providing the state to neural network and comparing the \n",
    "                                                                #actions with actions stored in memory and gather the experiences\n",
    "                next_action_b = self.policy(next_state_b) #using greedy epsilon policy to greedily get next actions\n",
    "                next_qsa_b = self.target_q_network(next_state_b).gather(1, next_action_b) #provide next state and next action to a target neural network\n",
    "                                                                                        #and gather its experiences\n",
    "                target_b = reward_b + ~done_b * gamma * next_qsa_b #discount the experiences of target network\n",
    "                loss = F.mse_loss(qsa_b, target_b) #find a Mean square error loss\n",
    "                self.q_network.zero_grad() #reset the gradients of the network\n",
    "                loss.backward() #calculate gradients using backward propogation\n",
    "                self.optim.step() # Iterate over all parameters (tensors) that are supposed \n",
    "                                # to be updated and use internally stored grad to update their values\n",
    "                loss.item() # get the loss\n",
    "                self.stats['MSE Loss'].append(loss.item())\n",
    "                    \n",
    "\n",
    "            state = next_state\n",
    "            ep_return += reward.item()\n",
    "\n",
    "        self.stats['Returns'].append(ep_return)\n",
    "\n",
    "        print (f'self.load state is {self.load_state}')\n",
    "        if self.load_state:\n",
    "            self.target_q_network.load_state_dict(self.q_network.state_dict()) #After every 10 episodes load state of original network to\n",
    "                                                                        # target network\n",
    "        return self.stats\n",
    "    \n",
    "    def act(self, observation, reward, done=False):\n",
    "        load_state = False\n",
    "        global episode_iter\n",
    "        if episode_iter % 10 == 0:\n",
    "            load_state = True\n",
    "        print(f'load state is :{load_state}')\n",
    "        stats = self.train_network(load_state)\n",
    "#         plot_stats(stats)\n",
    "        gym_obs = self.gym_env.observation_space.to_gym(observation)\n",
    "        conv_gym_obs = torch.from_numpy(gym_obs).unsqueeze(dim=0).float()\n",
    "        gym_act = torch.argmax(self.q_network(conv_gym_obs).detach(), dim=-1, keepdim=True)\n",
    "        print(f'Action is:{gym_act}')\n",
    "        grid2op_act = self.gym_env.action_space.from_gym(gym_act)\n",
    "        episode_iter += 1\n",
    "        return grid2op_act\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ae7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './training_data_track1'  # for demo only, use your own dataset\n",
    "SCENARIO_PATH = './training_data_track1/chronics'\n",
    "deep_sarsa_agent = DeepSarsaAgent(data_path=DATA_PATH, chronics_path=SCENARIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d30ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumed\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "episode_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5acd41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[45781]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[45781]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[45781]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[45781]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[45781]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[66372]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[25860]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[25860]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[95734]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[95734]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[124033]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[74163]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[74163]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[74163]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[74163]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[54220]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[4442]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[70231]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[70231]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[73784]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[125321]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[125321]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[125321]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[125321]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[74163]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[74163]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[17128]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[17128]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[17128]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[17128]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[17128]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[92302]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[94863]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[94863]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[33498]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[33498]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[33498]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[33498]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[33498]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[33498]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[34420]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[34420]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[34420]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[21108]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[21108]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[21108]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[40509]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[38131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[40509]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[125321]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[65159]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[65159]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[65159]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[65159]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[65159]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[65159]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[51820]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[51820]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[51820]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[51820]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[65159]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[67167]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[130422]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[130422]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[130422]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[130422]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[130422]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[58319]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[58319]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[58319]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[125321]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[15581]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[15581]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[15581]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[15581]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[127310]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[127310]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[127310]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[127310]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[127310]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[127310]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[15581]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[15581]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[124033]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[124033]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[6203]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6203]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6203]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6203]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6203]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6203]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6203]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6203]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6203]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[6203]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[15581]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[15581]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[15581]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[47329]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[132766]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[132766]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[33498]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[126692]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[126692]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[60131]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[8370]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[8370]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[8370]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[8370]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[8370]])\n",
      "load state is :True\n",
      "self.load state is False\n",
      "Action is:tensor([[8370]])\n",
      "load state is :False\n",
      "self.load state is False\n",
      "Action is:tensor([[8370]])\n",
      "The results for the custom agent are:\n",
      "\tFor chronics with id Scenario_august_dummly\n",
      "\t\t - cumulative reward: 529.481995\n",
      "\t\t - number of time steps completed: 20 / 20\n",
      "\tFor chronics with id Scenario_february_dummy\n",
      "\t\t - cumulative reward: 129.832642\n",
      "\t\t - number of time steps completed: 8 / 20\n",
      "\tFor chronics with id Scenario_august_dummly\n",
      "\t\t - cumulative reward: 439.603210\n",
      "\t\t - number of time steps completed: 20 / 20\n",
      "\tFor chronics with id Scenario_february_dummy\n",
      "\t\t - cumulative reward: 129.830933\n",
      "\t\t - number of time steps completed: 8 / 20\n",
      "\tFor chronics with id Scenario_august_dummly\n",
      "\t\t - cumulative reward: 529.597168\n",
      "\t\t - number of time steps completed: 20 / 20\n",
      "\tFor chronics with id Scenario_february_dummy\n",
      "\t\t - cumulative reward: 60.080872\n",
      "\t\t - number of time steps completed: 4 / 20\n",
      "\tFor chronics with id Scenario_august_dummly\n",
      "\t\t - cumulative reward: 439.599731\n",
      "\t\t - number of time steps completed: 20 / 20\n",
      "\tFor chronics with id Scenario_february_dummy\n",
      "\t\t - cumulative reward: 60.080872\n",
      "\t\t - number of time steps completed: 4 / 20\n",
      "\tFor chronics with id Scenario_august_dummly\n",
      "\t\t - cumulative reward: 529.509460\n",
      "\t\t - number of time steps completed: 20 / 20\n",
      "\tFor chronics with id Scenario_february_dummy\n",
      "\t\t - cumulative reward: 129.837250\n",
      "\t\t - number of time steps completed: 8 / 20\n"
     ]
    }
   ],
   "source": [
    "max_iter = 20 #customize\n",
    "from grid2op.Runner import Runner\n",
    "import os\n",
    "from grid2op.Reward import L2RPNReward\n",
    "from grid2op.Chronics import GridStateFromFileWithForecasts\n",
    "\n",
    "path_saved_data = './Result_DeepSarsa'\n",
    "if not os.path.exists(path_saved_data):\n",
    "    os.mkdir(path_saved_data)\n",
    "\n",
    "# env_name = \"l2rpn_neurips_2020_track1\"\n",
    "# env = grid2op.make(env_name)\n",
    "env = grid2op.make(dataset=DATA_PATH, chronics_path=SCENARIO_PATH)\n",
    "runner = Runner(**env.get_params_for_runner(),\n",
    "                agentInstance=deep_sarsa_agent, agentClass=None)\n",
    "res = runner.run(nb_episode=10, max_iter=max_iter, path_save=path_saved_data)\n",
    "print(\"The results for the custom agent are:\")\n",
    "for _, chron_name, cum_reward, nb_time_step, max_ts in res:\n",
    "    msg_tmp = \"\\tFor chronics with id {}\\n\".format(chron_name)\n",
    "    msg_tmp += \"\\t\\t - cumulative reward: {:.6f}\\n\".format(cum_reward)\n",
    "    msg_tmp += \"\\t\\t - number of time steps completed: {:.0f} / {:.0f}\".format(nb_time_step, max_ts)\n",
    "    print(msg_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "490767b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NetworkXError",
     "evalue": "random_state_index is incorrect",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\networkx\\utils\\decorators.py\u001b[0m in \u001b[0;36m_random_state\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             \u001b[0mrandom_state_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_state_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNetworkXError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-aadbfa1b8b3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mep_replay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEpisodeReplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_saved_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchron_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcum_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_time_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_ts\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     ep_replay.replay_episode(chron_name,  # which chronic was started\n\u001b[0m\u001b[0;32m      7\u001b[0m                              \u001b[0mgif_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgif_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Name of the gif file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                              \u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# dont wait before rendering each frames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\windows\\system32\\grid2op\\grid2op\\Episode\\EpisodeReplay.py\u001b[0m in \u001b[0;36mreplay_episode\u001b[1;34m(self, episode_id, fps, gif_name, display, start_step, end_step, line_info, load_info, gen_info, resolution)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;31m# Create a plotter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresolution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         plot_runner = PlotMatplot(\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepisode_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\windows\\system32\\grid2op\\grid2op\\PlotGrid\\PlotMatplot.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, observation_space, width, height, grid_layout, dpi, scale, bus_radius, sub_radius, load_radius, load_name, load_id, load_resolution, gen_radius, gen_name, gen_id, gen_resolution, storage_resolution, line_name, line_id)\u001b[0m\n\u001b[0;32m    175\u001b[0m     ):\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_layout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sub_radius\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub_radius\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\windows\\system32\\grid2op\\grid2op\\PlotGrid\\BasePlot.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, observation_space, width, height, scale, grid_layout, parallel_spacing)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gens_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"p\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"v\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grid_layout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_grid_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_layout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;31m# Augment observation_space with dummy observation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\windows\\system32\\grid2op\\grid2op\\PlotGrid\\BasePlot.py\u001b[0m in \u001b[0;36mcompute_grid_layout\u001b[1;34m(self, observation_space, grid_layout)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;31m# Compute loads and gens positions using a default implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_layout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_grid_layout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         return layout_obs_sub_load_and_gen(\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_initial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         )\n",
      "\u001b[1;32mc:\\windows\\system32\\grid2op\\grid2op\\PlotGrid\\LayoutUtil.py\u001b[0m in \u001b[0;36mlayout_obs_sub_load_and_gen\u001b[1;34m(obs, scale, use_initial, parallel_spacing)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;31m# Use Fruchterman-Reingold algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         kkl = nx.spring_layout(\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_layout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\networkx\\utils\\decorators.py\u001b[0m in \u001b[0;36m_random_state\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetworkXError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"random_state_index must be an integer\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetworkXError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"random_state_index is incorrect\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[1;31m# Create a numpy.random.RandomState instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNetworkXError\u001b[0m: random_state_index is incorrect"
     ]
    }
   ],
   "source": [
    "from grid2op.Episode import EpisodeReplay\n",
    "\n",
    "gif_name = \"episode\"   \n",
    "ep_replay = EpisodeReplay(agent_path=path_saved_data)\n",
    "for _, chron_name, cum_reward, nb_time_step, max_ts in res:\n",
    "    ep_replay.replay_episode(chron_name,  # which chronic was started\n",
    "                             gif_name=gif_name, # Name of the gif file\n",
    "                             display=False,  # dont wait before rendering each frames\n",
    "                             fps=3.0)  # limit to 3 frames per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1001195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a32df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20adf620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52769470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
